{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16ed6c0",
   "metadata": {},
   "source": [
    "# Watchtower\n",
    "\n",
    "The Hydras are finally about to be defeated. This watchtower helps monitor the impact of the Hydras' deaths on the rest of the world.\n",
    "\n",
    "## Features of this script\n",
    "\n",
    "1. Query some Nebula Crawler database\n",
    "2. Save useful information of the database on disk\n",
    "3. Load database information from disk\n",
    "4. Generate plots for selected crawls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931469f",
   "metadata": {},
   "source": [
    "## Nebula DB queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "988820be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2, math\n",
    "from sshtunnel import SSHTunnelForwarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ef28508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_peerids():\n",
    "    cur.execute(\"select id,multi_hash from peers;\")\n",
    "    peerids = {x[0]:x[1] for x in cur.fetchall()} # nebulaID -> peerID\n",
    "        \n",
    "    to_add = []\n",
    "    with open(peerids_filename, 'r') as f:\n",
    "        # read existing mappings\n",
    "        lines = f.readlines()\n",
    "        # get the nebula IDs only\n",
    "        nebIDs = [int(line.split(',')[0]) for line in lines]\n",
    "        \n",
    "        for p in peerids:\n",
    "            # find missing peers\n",
    "            if p not in nebIDs:\n",
    "                # add them to to_add\n",
    "                to_add.append(str(p)+','+peerids[p]+'\\n')\n",
    "                                    \n",
    "    with open(peerids_filename, 'a') as f:\n",
    "        f.writelines(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59b32449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crawl_ids():\n",
    "    cur.execute(\"select id from crawls;\")\n",
    "    return [c[0] for c in cur.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bf27b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_crawl(crawl_id, filename):\n",
    "    cur.execute(\"select peer_id,neighbor_ids from neighbors where crawl_id=\"+str(crawl_id)+\";\")\n",
    "    neighbors_rel = cur.fetchall()\n",
    "    \n",
    "    nebula_peers = []\n",
    "    for (nebula_id, neighbors) in neighbors_rel:\n",
    "        s = str(nebula_id) + ','\n",
    "        for n in neighbors:\n",
    "            s += str(n) + ','\n",
    "        s = s[:-1] + '\\n'\n",
    "        nebula_peers.append(s)\n",
    "\n",
    "    f = open(filename, 'w')\n",
    "    f.writelines(nebula_peers)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23f999c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_filename(db_identifier, crawl_id):\n",
    "    if crawl_id == 0:\n",
    "        crawl = \"000\"\n",
    "    elif crawl_id < 100:\n",
    "        l = int(math.log10(crawl_id))\n",
    "        crawl = (2-l) * '0' + str(crawl_id)\n",
    "    else:\n",
    "        crawl = str(crawl_id)\n",
    "    return data_folder + str(db_identifier) + \"-crawl-\" + crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c06bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/\"\n",
    "peerids_filename = data_folder + \"peerids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76c59a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = {\n",
    "    \"ap_southeast_1_offset_4\" : \"13.212.87.17\",\n",
    "    \"ap_southeast_1_offset_9\" : \"13.212.199.68\",\n",
    "    \"eu_central_1_offset_0\" : \"3.69.43.200\",\n",
    "    \"eu_central_1_offset_5\" : \"18.192.183.185\",\n",
    "    \"sa_east_1_offset_3\" : \"18.231.132.66\",\n",
    "    \"sa_east_1_offset_8\" : \"15.229.22.158\",\n",
    "    \"us_east_1_offset_2\" : \"44.200.54.223\",\n",
    "    \"us_east_1_offset_7\" : \"34.205.54.199\",\n",
    "    \"us_west_1_offset_1\" : \"54.219.175.30\",\n",
    "    \"us_west_1_offset_6\" : \"54.153.60.176\"\n",
    "}\n",
    "host_username = \"ubuntu\"\n",
    "ssh_key_location = \".ssh/id_rsa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "acda7660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:14,451| ERROR   | Password is required for key /home/guissou/.ssh/id_ed25519\n"
     ]
    }
   ],
   "source": [
    "ssh_tunnel = SSHTunnelForwarder(\n",
    "    \"13.212.87.17\",\n",
    "    ssh_username=host_username,\n",
    "    ssh_pkey=ssh_key_location,\n",
    "    ssh_private_key_password=\"\",\n",
    "    remote_bind_address=(\"13.212.87.17\", 5432)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a853db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_info = \"host=127.0.0.1 dbname=nebula user=nebula password=password\"\n",
    "db_identifier = \"db0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "330fe903",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(db_info)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df1a3495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_crawl_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72a1286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_ids_to_save = [1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61e34485",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_peerids()\n",
    "for i in crawl_ids_to_save:\n",
    "        store_crawl(i, crawl_filename(db_identifier, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa2e31",
   "metadata": {},
   "source": [
    "## Load crawler data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b91a276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_ids_to_load = ['db0-crawl-001', 'db0-crawl-003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c0f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nebulaID -> peerID map\n",
    "with open(peerids_filename, 'r') as file:\n",
    "    nebulaid_peerid = {line.split(',')[0]:line.split(',')[1][:-1] for line in file.readlines()}\n",
    "    # [:-1] removes the trailing '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7ea39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nebula_neighbors = []\n",
    "for crawl_filename in crawl_ids_to_load:\n",
    "    # load neighbors for each crawl\n",
    "    with open(data_folder+crawl_filename, 'r') as file:\n",
    "        nebula_neighbors.append({line.split(',')[0]:line.split(',')[1:][:-1] for line in file.readlines()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183088f",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "556f531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multihash as mh\n",
    "import hashlib as hl\n",
    "from binary_trie import Trie, bytes_to_bitstring, int_to_bitstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "324984ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a peer_id (e.g 12D3KooWEZXjE41uU4EL2gpkAQeDXYok6wghN7wwNVPF5bwkaNfS) to its\n",
    "# sha256 hash representation (256 bits), used as kademlia identifier\n",
    "def multihash_to_kad_id(peer_id: str) -> bytes:  \n",
    "    multi_hash = mh.from_b58_string(peer_id)\n",
    "    return hl.sha256(multi_hash).digest()\n",
    "\n",
    "# XOR two bitstring of equal size, the size doesn't need to be a multiple of 8\n",
    "def xor_bitstring(bs0: str, bs1: str) -> str:\n",
    "    s = \"\"\n",
    "    if len(bs0) == len(bs1):\n",
    "        for i in range(len(bs0)):\n",
    "            if bs0[i]==bs1[i]:\n",
    "                s+='0'\n",
    "            else:\n",
    "                s+='1'\n",
    "    return s\n",
    "\n",
    "# returns the XOR distance (in bytes) between the two provided bytes arrays\n",
    "def xor_distance(bytes0: bytes, bytes1: bytes):\n",
    "    xor=bytearray()\n",
    "    maxlen=max(len(bytes0), len(bytes1))\n",
    "\n",
    "    for i in range(maxlen):\n",
    "        byte0 = bytes0[i if len(bytes0)>len(bytes1) else i-len(bytes1)+len(bytes0)] if i >= maxlen-len(bytes0) else 0\n",
    "        byte1 = bytes1[i if len(bytes1)>len(bytes0) else i-len(bytes0)+len(bytes1)] if i >= maxlen-len(bytes1) else 0\n",
    "        xor.append(byte0 ^ byte1)\n",
    "\n",
    "    return bytes(xor)\n",
    "\n",
    "# get the corresponding k-bucket for the given XOR distance in bytes\n",
    "def bucket_number_for_distance(d: bytes) -> int:\n",
    "    count=0\n",
    "    # iterate on the bytes from left to right\n",
    "    for b in d:\n",
    "        # while the byte==0, add 8 (bits) to the counter\n",
    "        count+=8\n",
    "        if b!=0:\n",
    "            # at the first non null byte, shift right until this byte==0\n",
    "            while b!=0:\n",
    "                b>>=1\n",
    "                # for each right shift, remove 1 to counter\n",
    "                count-=1\n",
    "            break\n",
    "    # return the length of the byte string minus the number of leading 0 bits\n",
    "    return 256-(8*len(d)-count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "534aec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NebulaPeer:\n",
    "    def __init__(self, nebula_id, peer_id, neighbors_ids):\n",
    "        self.nebula_id = nebula_id\n",
    "        self.peer_id = peer_id\n",
    "        self.neighbors_ids = neighbors_ids\n",
    "        \n",
    "        self.key = multihash_to_kad_id(peer_id)\n",
    "        \n",
    "        self.alive = len(neighbors_ids)>0\n",
    "        \n",
    "        self.buckets = [[] for _ in range(257)]\n",
    "        self.neighbors = {}\n",
    "        \n",
    "    def distance(self, p):\n",
    "        return xor_distance(self.key, p.key)\n",
    "        \n",
    "    def addNeighbor(self, peer):\n",
    "        if bytes_to_bitstring(peer.key) not in self.neighbors:\n",
    "            self.neighbors[bytes_to_bitstring(peer.key)] = peer\n",
    "            self.buckets[bucket_number_for_distance(self.distance(peer))].append(peer)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"nebula_id: \"+str(self.nebula_id)+\", peer_id: \"+str(self.peer_id)+\", neighbors: \"+str(self.neighbors_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970aff69",
   "metadata": {},
   "source": [
    "## Building the data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7d2cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c3d4f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crawls_peers = [] # contains all diable peers for each crawl\n",
    "all_crawls_all_peers = [] # contains all peers for each crawl (including undiable ones)\n",
    "all_crawls_peers_maps = []\n",
    "\n",
    "i = 0\n",
    "for nebula in nebula_neighbors:\n",
    "    \n",
    "    # build all peers\n",
    "    peers = [NebulaPeer(n, nebulaid_peerid[n], nebula[n]) for n in nebula]\n",
    "    # make a map for easy access nebulaID -> NebulaPeer\n",
    "    peers_map = {p.nebula_id:p for p in peers}\n",
    "    \n",
    "    new_peers = {}\n",
    "    for p in peers:\n",
    "        for n in p.neighbors_ids:\n",
    "            if n not in peers_map and n not in new_peers:\n",
    "                np = NebulaPeer(n, nebulaid_peerid[n], [])\n",
    "                new_peers[n] = np\n",
    "                p.addNeighbor(np)\n",
    "            elif n in new_peers:\n",
    "                p.addNeighbor(new_peers[n])\n",
    "            else:\n",
    "                p.addNeighbor(peers_map[n])\n",
    "        \n",
    "    all_crawls_peers.append(peers)\n",
    "    all_crawls_peers_maps.append(peers_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d7ae15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
