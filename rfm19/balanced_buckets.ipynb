{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced buckets\n",
    "\n",
    "Simulation of the benefit in the number of hop of having balanced DHT buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binary_trie import Trie, bytes_to_bitstring, int_to_bitstring, bitstring_to_int, bitstring_to_bytes\n",
    "import multihash as mh\n",
    "import hashlib as hl\n",
    "import math, os, random\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximal number of buckets in a peer's routing table,\n",
    "# equivalent to bit size of the keyspace\n",
    "n_buckets = 256\n",
    "\n",
    "# length of a kademlia key in bytes\n",
    "keylen = 32\n",
    "\n",
    "# bucket containing the closest peer\n",
    "closest_bucket = 20\n",
    "\n",
    "# number of peers participating in the network\n",
    "peers_number = 25000\n",
    "\n",
    "# ipfs dht concurrency factor, defining how many\n",
    "# peers are contacted concurrently at each hop\n",
    "concurrency = 10\n",
    "\n",
    "# replication factor for all data in the ipfs dht\n",
    "repl = 20\n",
    "\n",
    "# size of a bucket in a peer's routing table\n",
    "bucket_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a random key in the kademlia keyspace\n",
    "def random_key():\n",
    "    return os.urandom(keylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_int(b: bytes) -> int:\n",
    "    return int.from_bytes(b, byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bxor(b1, b2):\n",
    "    n_b1 = np.frombuffer(b1, dtype='uint8')\n",
    "    n_b2 = np.frombuffer(b2, dtype='uint8')\n",
    "\n",
    "    return (n_b1 ^ n_b2).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dist(bs0, bs1: bytes) -> int:\n",
    "    xored = bxor(bs0, bs1)\n",
    "    dist = byte_to_int(xored)\n",
    "    if dist == 0:\n",
    "        return n_buckets\n",
    "    return n_buckets-math.floor(math.log2(dist))-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest(t: Trie, k: bytes, n: int):\n",
    "    if t.size == 0:\n",
    "        # TODO: remove me\n",
    "        print(\"error nil trie\")\n",
    "        return\n",
    "    closest = t.n_closest_keys(bytes_to_bitstring(k, l=n_buckets), n)\n",
    "    return [bitstring_to_bytes(bs) for bs in closest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_bucket() is given as input a binary trie t, and an integer n,\n",
    "# it returns a balanced list of n random keys. The list is considered as\n",
    "# balanced because, if possible it will contain the same number of keys,\n",
    "# starting with the prefix \"0\" and \"1\", the same number of prefixes \"00\",\n",
    "# \"01\", \"10\", \"11\" etc.\n",
    "# this function is recursive\n",
    "def balance_bucket(t: Trie, n: int):\n",
    "    if n == 0 or t is None:\n",
    "        # invalid parameters\n",
    "        return []\n",
    "\n",
    "    # number of keys wanted with prefix \"0\" and \"1\"\n",
    "    half = math.ceil(n/2)\n",
    "\n",
    "    # if at least one branc is undefined, we reached a leaf\n",
    "    if t.branch[0] is None or t.branch[1] is None:\n",
    "        # return a list containing the leaf's key\n",
    "        return [t.key]\n",
    "    # if both branches have enough candidates\n",
    "    elif t.branch[0].size >= half and t.branch[1].size >= half:\n",
    "        add0, add1 = 0, 0\n",
    "        # odd number of peers to return, need to select a branch\n",
    "        # to have 1 additional peer\n",
    "        if n % 2 == 1:\n",
    "            if random.randint(0, 1) == 0:\n",
    "                add0 += 1\n",
    "            else:\n",
    "                add1 += 1\n",
    "        # return the union of the n/2 balanced peers starting with\n",
    "        # prefix \"0\" and the n/2 starting with prefix \"1\"\n",
    "        return balance_bucket(t.branch[0], half-add0) + balance_bucket(t.branch[1], half-add1)\n",
    "    # less than half keys with prefix \"1\"\n",
    "    elif t.branch[0].size >= half:\n",
    "        b1 = t.branch[1].size\n",
    "        # return all keys with prefix \"1\", and a balanced list from\n",
    "        # bucket 0\n",
    "        return balance_bucket(t.branch[0], n-b1) + balance_bucket(t.branch[1], b1)\n",
    "    # less than half keys with prefix \"0\"\n",
    "    elif t.branch[1].size >= half:\n",
    "        b0 = t.branch[0].size\n",
    "        # return all keys with prefix \"0\", and a balanced list from\n",
    "        # with prefix \"1\"\n",
    "        return balance_bucket(t.branch[0], b0) + balance_bucket(t.branch[1], n-b0)\n",
    "    else:\n",
    "        # there are less than n keys in t, return all keys\n",
    "        return t.match_prefix_keys(prefix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sim(n_peers, bucket_size):\n",
    "    # binary trie storing all peers ids\n",
    "    sim_trie = Trie()\n",
    "    # list of peers for this simulation\n",
    "    sim_peers = []\n",
    "\n",
    "    # routing table of the simluation with random buckets\n",
    "    sim_peers_random = {}\n",
    "    # routing table of the simulation with balanced buckets\n",
    "    sim_peers_balanced = {}\n",
    "\n",
    "    # generate random peerids and populate the binary trie\n",
    "    for _ in range(n_peers):\n",
    "        # generate random peerid\n",
    "        peerid = random_key()\n",
    "        # add peerid to peer trie\n",
    "        while not sim_trie.add(bytes_to_bitstring(peerid)):\n",
    "            # add returns false if key already in trie\n",
    "            # generate new identity\n",
    "            peerid = random_key()\n",
    "\n",
    "        # add peerid to list of peerids\n",
    "        sim_peers.append(peerid)\n",
    "\n",
    "        # create entry for peerid in both simulations routing tables\n",
    "        sim_peers_random[peerid] = {}\n",
    "        sim_peers_balanced[peerid] = {}\n",
    "\n",
    "    # iterate on all possible buckets, large to small buckets, 0 prefix to 1 prefix\n",
    "    for bid in range(closest_bucket):\n",
    "        for i in range(2**(bid+1)):\n",
    "            # prefix of the current bucket\n",
    "            bucket_prefix = int_to_bitstring(i, bid+1)\n",
    "            # all peers falling in this bucket\n",
    "            candidates = sim_trie.match_prefix_keys(bucket_prefix)\n",
    "\n",
    "            # if no candidates, continue\n",
    "            if len(candidates) == 0:\n",
    "                continue\n",
    "\n",
    "            # flip last bit\n",
    "            target_prefix = bucket_prefix[:-1]+str(1-int(bucket_prefix[-1]))\n",
    "\n",
    "            # targets are peers that could use the candidates (of the current bucket)\n",
    "            # in their routing table\n",
    "            targets = sim_trie.match_prefix_keys(target_prefix)\n",
    "\n",
    "\n",
    "            # bucket root is the subtrie representing the bucket\n",
    "            bucket_root = sim_trie.find_trie(bucket_prefix)\n",
    "            if bucket_root is None:\n",
    "                # bucket root could be undefined if subkey not in the trie\n",
    "                # we need to find the closest child\n",
    "                i = 0\n",
    "                while bucket_root is None:\n",
    "                    i += 1\n",
    "                    # find the first existing parent\n",
    "                    bucket_root = sim_trie.find_trie(bucket_prefix[:-i])\n",
    "                # select the appropriate child as the bucket root\n",
    "                bucket_root = bucket_root.branch[int(bucket_prefix[-i+1])]\n",
    "\n",
    "            # iterate on all targets, and define which candidates are selected\n",
    "            # for their bucket\n",
    "            for t in targets:\n",
    "                # if more than `bucket_size` candidates, select `bucket_size` of them\n",
    "                # at random, else take them all\n",
    "                random_bucket = [bitstring_to_bytes(p) for p in \n",
    "                    random.sample(candidates, min(bucket_size, len(candidates)))]\n",
    "                # add these peers to t's routing table, in bucket bid\n",
    "                sim_peers_random[bitstring_to_bytes(t)][bid] = random_bucket\n",
    "\n",
    "                # randomly select candidates in a balanced manner\n",
    "                balanced_bucket = [bitstring_to_bytes(p) for p in balance_bucket(bucket_root, min(bucket_size, len(candidates)))]\n",
    "                # add these peers to t's routing table, in bucket bid\n",
    "                sim_peers_balanced[bitstring_to_bytes(t)][bid] = balanced_bucket\n",
    "\n",
    "    return sim_trie, sim_peers, sim_peers_random, sim_peers_balanced\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58.4 s for bucket_size = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_n_hops(peer, key, peers, trie, concurrency, repl):\n",
    "    # closest peers are the peers storing data associated with key\n",
    "    closest_peers = n_closest(trie, key, repl)\n",
    "\n",
    "    # hop count\n",
    "    hop = 0\n",
    "    if peer in closest_peers:\n",
    "        # if peer store is among the closest peers, 0 hop\n",
    "        return hop\n",
    "\n",
    "    # binary trie helping find the closest peers to key in \n",
    "    # the node's routing table\n",
    "    req_trie = Trie()\n",
    "    # bucket id, corresponding to key\n",
    "    bid = log_dist(peer, key)\n",
    "\n",
    "    if bid in peers[peer] and len(peers[peer][bid]) > 0:\n",
    "        # if this bucket is populated, add peers to req_trie\n",
    "        for peer_neighbor in peers[peer][bid]:\n",
    "            req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "    else:\n",
    "        buckets = list(peers[peer].keys())\n",
    "        found_higher = False\n",
    "        for b in range(bid+1, max(buckets)+1):\n",
    "            if b in buckets and len(peers[peer][b]) > 0:\n",
    "                for peer_neighbor in peers[peer][b]:\n",
    "                    req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                    found_higher = True\n",
    "        if not found_higher:\n",
    "            for b in range(bid-1, -1, -1):\n",
    "                if b in buckets and len(peers[peer][b]) > 0:\n",
    "                    for peer_neighbor in peers[peer][b]:\n",
    "                        req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                    break # we are only interested in the closest bucket\n",
    "                \n",
    "    req_peers = n_closest(req_trie, key, concurrency)\n",
    "\n",
    "    while True:\n",
    "        hop += 1\n",
    "        for c in closest_peers:\n",
    "            if c in req_peers:\n",
    "                return hop\n",
    "\n",
    "        req_trie = Trie()\n",
    "        for p in req_peers:\n",
    "            bid = log_dist(p, key)\n",
    "\n",
    "            if bid in peers[p] and len(peers[p][bid]) > 0:\n",
    "                for peer_neighbor in peers[p][bid]:\n",
    "                    req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "            else:\n",
    "                buckets = list(peers[p].keys())\n",
    "                found_higher = False\n",
    "                for b in range(bid+1, max(buckets)+1):\n",
    "                    if b in buckets and len(peers[p][b]) > 0:\n",
    "                        for peer_neighbor in peers[p][b]:\n",
    "                            req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                            found_higher = True\n",
    "                if not found_higher:\n",
    "                    for b in range(bid-1, -1, -1):\n",
    "                        if b in buckets and len(peers[p][b]) > 0:\n",
    "                            for peer_neighbor in peers[p][b]:\n",
    "                                req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                            break # we are only interested in the closest bucket\n",
    "                    \n",
    "        req_peers = n_closest(req_trie, key, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(peers_number, bucket_size, concurrency, repl, n_requests, iterations=1):\n",
    "    results = []\n",
    "    for _ in range(iterations):\n",
    "        sim_trie, sim_peers, sim_peers_random, sim_peers_balanced = generate_sim(peers_number, bucket_size)\n",
    "\n",
    "        sim_random_hop_count = []\n",
    "        for i in range(n_requests):\n",
    "            peer = random.choice(sim_peers)\n",
    "            key = random_key()\n",
    "            n_hop = lookup_n_hops(peer, key, sim_peers_random, sim_trie, concurrency, repl)\n",
    "            sim_random_hop_count.append(n_hop)\n",
    "            \n",
    "        sim_balanced_hop_count = []\n",
    "        for i in range(n_requests):\n",
    "            peer = random.choice(sim_peers)\n",
    "            key = random_key()\n",
    "            n_hop = lookup_n_hops(peer, key, sim_peers_balanced, sim_trie, concurrency, repl)\n",
    "            sim_balanced_hop_count.append(n_hop)\n",
    "\n",
    "        sim_avg_random = sum(sim_random_hop_count)/len(sim_random_hop_count)\n",
    "        sim_avg_balanced = sum(sim_balanced_hop_count)/len(sim_balanced_hop_count)\n",
    "\n",
    "        results.append((sim_avg_random, sim_avg_balanced))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_sim(peers_number=25000, bucket_size=20, concurrency=10, repl=20, n_requests=10000, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.9292, 1.8984),\n",
       " (1.9224, 1.8897),\n",
       " (1.9297, 1.8887),\n",
       " (1.9287, 1.8856),\n",
       " (1.9263, 1.894)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_random = 0\n",
    "sum_balanced = 0\n",
    "for r0, r1 in results:\n",
    "    sum_random += r0\n",
    "    sum_balanced += r1\n",
    "avg_random = sum_random / len(results)\n",
    "avg_balanced = sum_balanced / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average random buckets: 1.92726\n",
      "Average balanced buckets: 1.89128\n",
      "Improvement: 1.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"Average random buckets:\", avg_random)\n",
    "print(\"Average balanced buckets:\", avg_balanced)\n",
    "print(\"Improvement: \"+str(round(100*(1-avg_balanced/avg_random), 2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple bucket size simulation\n",
    "# not realistic because all queries are exactly concurrent\n",
    "\n",
    "results = {}\n",
    "for i in range(10, 110, 10):\n",
    "    results[i] = run_sim(peers_number=25000, bucket_size=i, concurrency=10, repl=20, n_requests=10000, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: [(2.173, 2.0841),\n",
       "  (2.1698, 2.0799),\n",
       "  (2.1568, 2.0891),\n",
       "  (2.1686, 2.0895),\n",
       "  (2.159, 2.0849)],\n",
       " 20: [(1.9298, 1.8848),\n",
       "  (1.9234, 1.8918),\n",
       "  (1.9229, 1.8925),\n",
       "  (1.9262, 1.8952),\n",
       "  (1.9292, 1.891)],\n",
       " 30: [(1.8677, 1.8426),\n",
       "  (1.8679, 1.8404),\n",
       "  (1.8677, 1.8459),\n",
       "  (1.8658, 1.8457),\n",
       "  (1.8738, 1.8385)],\n",
       " 40: [(1.8329, 1.8125),\n",
       "  (1.838, 1.8051),\n",
       "  (1.8326, 1.8054),\n",
       "  (1.8323, 1.8099),\n",
       "  (1.8338, 1.8123)],\n",
       " 50: [(1.8062, 1.7731),\n",
       "  (1.8019, 1.7749),\n",
       "  (1.8087, 1.7795),\n",
       "  (1.8054, 1.7773),\n",
       "  (1.8083, 1.7721)],\n",
       " 60: [(1.7664, 1.742),\n",
       "  (1.7862, 1.7458),\n",
       "  (1.7789, 1.7396),\n",
       "  (1.7823, 1.7488),\n",
       "  (1.7751, 1.7394)],\n",
       " 70: [(1.7575, 1.7157),\n",
       "  (1.7575, 1.7133),\n",
       "  (1.7561, 1.7039),\n",
       "  (1.7551, 1.7182),\n",
       "  (1.7546, 1.7122)],\n",
       " 80: [(1.7316, 1.6825),\n",
       "  (1.7265, 1.6859),\n",
       "  (1.7343, 1.6871),\n",
       "  (1.7285, 1.6769),\n",
       "  (1.7239, 1.6872)],\n",
       " 90: [(1.7144, 1.6609),\n",
       "  (1.7039, 1.6495),\n",
       "  (1.7105, 1.6741),\n",
       "  (1.7069, 1.6662),\n",
       "  (1.7074, 1.6678)],\n",
       " 100: [(1.7009, 1.6315),\n",
       "  (1.6875, 1.6344),\n",
       "  (1.6958, 1.6317),\n",
       "  (1.6899, 1.6345),\n",
       "  (1.6888, 1.6312)]}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = {}\n",
    "for r in results:\n",
    "    sum0 = 0\n",
    "    sum1 = 0\n",
    "    for h0, h1 in results[r]:\n",
    "        sum0 += h0\n",
    "        sum1 += h1\n",
    "    avg0 = sum0/len(results[r])\n",
    "    avg1 = sum1/len(results[r])\n",
    "    avg_results[r] = (avg0, avg1, str(round(100*(1-avg1/avg0), 2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: (2.1654400000000003, 2.0855000000000006, '3.69%'),\n",
       " 20: (1.9263000000000001, 1.8910600000000002, '1.83%'),\n",
       " 30: (1.8685800000000001, 1.8426200000000001, '1.39%'),\n",
       " 40: (1.8339199999999998, 1.80904, '1.36%'),\n",
       " 50: (1.8061, 1.7753800000000002, '1.7%'),\n",
       " 60: (1.77778, 1.74312, '1.95%'),\n",
       " 70: (1.7561600000000002, 1.71266, '2.48%'),\n",
       " 80: (1.72896, 1.68392, '2.61%'),\n",
       " 90: (1.7086200000000002, 1.6637, '2.63%'),\n",
       " 100: (1.69258, 1.6326600000000002, '3.54%')}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Simulation 0\n",
    "\n",
    "Parameters: \n",
    "```python\n",
    "peers_number=25000, bucket_size=20, concurrency=10, repl=20, n_requests=10000, iterations=5\n",
    "```\n",
    "\n",
    "results: \n",
    "```python\n",
    "[(1.9292, 1.8984),\n",
    " (1.9224, 1.8897),\n",
    " (1.9297, 1.8887),\n",
    " (1.9287, 1.8856),\n",
    " (1.9263, 1.894)]\n",
    "\n",
    "Average random buckets: 1.92726\n",
    "Average balanced buckets: 1.89128\n",
    "Improvement: 1.87%\n",
    "\n",
    "Time: 10 min\n",
    "```\n",
    "\n",
    "## Simulation 1\n",
    "\n",
    "Parameters:\n",
    "```python\n",
    "results = {}\n",
    "for i in range(10, 110, 10):\n",
    "    results[i] = run_sim(peers_number=25000, bucket_size=i, concurrency=10, repl=20, n_requests=10000, iterations=5)\n",
    "```\n",
    "results: \n",
    "```python\n",
    "{10: [(2.173, 2.0841),\n",
    "  (2.1698, 2.0799),\n",
    "  (2.1568, 2.0891),\n",
    "  (2.1686, 2.0895),\n",
    "  (2.159, 2.0849)],\n",
    " 20: [(1.9298, 1.8848),\n",
    "  (1.9234, 1.8918),\n",
    "  (1.9229, 1.8925),\n",
    "  (1.9262, 1.8952),\n",
    "  (1.9292, 1.891)],\n",
    " 30: [(1.8677, 1.8426),\n",
    "  (1.8679, 1.8404),\n",
    "  (1.8677, 1.8459),\n",
    "  (1.8658, 1.8457),\n",
    "  (1.8738, 1.8385)],\n",
    " 40: [(1.8329, 1.8125),\n",
    "  (1.838, 1.8051),\n",
    "  (1.8326, 1.8054),\n",
    "  (1.8323, 1.8099),\n",
    "  (1.8338, 1.8123)],\n",
    " 50: [(1.8062, 1.7731),\n",
    "  (1.8019, 1.7749),\n",
    "  (1.8087, 1.7795),\n",
    "  (1.8054, 1.7773),\n",
    "  (1.8083, 1.7721)],\n",
    " 60: [(1.7664, 1.742),\n",
    "  (1.7862, 1.7458),\n",
    "  (1.7789, 1.7396),\n",
    "  (1.7823, 1.7488),\n",
    "  (1.7751, 1.7394)],\n",
    " 70: [(1.7575, 1.7157),\n",
    "  (1.7575, 1.7133),\n",
    "  (1.7561, 1.7039),\n",
    "  (1.7551, 1.7182),\n",
    "  (1.7546, 1.7122)],\n",
    " 80: [(1.7316, 1.6825),\n",
    "  (1.7265, 1.6859),\n",
    "  (1.7343, 1.6871),\n",
    "  (1.7285, 1.6769),\n",
    "  (1.7239, 1.6872)],\n",
    " 90: [(1.7144, 1.6609),\n",
    "  (1.7039, 1.6495),\n",
    "  (1.7105, 1.6741),\n",
    "  (1.7069, 1.6662),\n",
    "  (1.7074, 1.6678)],\n",
    " 100: [(1.7009, 1.6315),\n",
    "  (1.6875, 1.6344),\n",
    "  (1.6958, 1.6317),\n",
    "  (1.6899, 1.6345),\n",
    "  (1.6888, 1.6312)]}\n",
    "\n",
    "{10: (2.1654400000000003, 2.0855000000000006, '3.69%'),\n",
    " 20: (1.9263000000000001, 1.8910600000000002, '1.83%'),\n",
    " 30: (1.8685800000000001, 1.8426200000000001, '1.39%'),\n",
    " 40: (1.8339199999999998, 1.80904, '1.36%'),\n",
    " 50: (1.8061, 1.7753800000000002, '1.7%'),\n",
    " 60: (1.77778, 1.74312, '1.95%'),\n",
    " 70: (1.7561600000000002, 1.71266, '2.48%'),\n",
    " 80: (1.72896, 1.68392, '2.61%'),\n",
    " 90: (1.7086200000000002, 1.6637, '2.63%'),\n",
    " 100: (1.69258, 1.6326600000000002, '3.54%')}\n",
    "\n",
    " Time: 217 min\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_random_hop_count = []\n",
    "for i in range(10000):\n",
    "    peer = random.choice(sim_peers)\n",
    "    key = random_key()\n",
    "    n_hop = lookup_n_hops(peer, key, sim_peers_random, sim_trie, concurrency, repl)\n",
    "    sim_random_hop_count.append(n_hop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9227"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_avg_random = sum(sim_random_hop_count)/len(sim_random_hop_count)\n",
    "sim_avg_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_balanced_hop_count = []\n",
    "for i in range(10000):\n",
    "    peer = random.choice(sim_peers)\n",
    "    key = random_key()\n",
    "    n_hop = lookup_n_hops(peer, key, sim_peers_balanced, sim_trie, concurrency, repl)\n",
    "    sim_balanced_hop_count.append(n_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8973"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_avg_balanced = sum(sim_balanced_hop_count)/len(sim_balanced_hop_count)\n",
    "sim_avg_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average random buckets 1.9227\n",
      "Average balanced buckets 1.8973\n",
      "0.013210589275498008\n"
     ]
    }
   ],
   "source": [
    "print(\"Average random buckets\", sim_avg_random)\n",
    "print(\"Average balanced buckets\", sim_avg_balanced)\n",
    "print(1-sim_avg_balanced/sim_avg_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
