{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced buckets\n",
    "\n",
    "Simulation of the benefit in the number of hop of having balanced DHT buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binary_trie import Trie, bytes_to_bitstring, int_to_bitstring, bitstring_to_int, bitstring_to_bytes\n",
    "import multihash as mh\n",
    "import hashlib as hl\n",
    "import math, os, random\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximal number of buckets in a peer's routing table,\n",
    "# equivalent to bit size of the keyspace\n",
    "n_buckets = 256\n",
    "\n",
    "# length of a kademlia key in bytes\n",
    "keylen = 32\n",
    "\n",
    "# bucket containing the closest peer\n",
    "closest_bucket = 20\n",
    "\n",
    "# number of peers participating in the network\n",
    "peers_number = 25000\n",
    "\n",
    "# ipfs dht concurrency factor, defining how many\n",
    "# peers are contacted concurrently at each hop\n",
    "concurrency = 10\n",
    "\n",
    "# replication factor for all data in the ipfs dht\n",
    "repl = 20\n",
    "\n",
    "# size of a bucket in a peer's routing table\n",
    "bucket_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a random key in the kademlia keyspace\n",
    "def random_key():\n",
    "    return os.urandom(keylen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_to_int(b: bytes) -> int:\n",
    "    return int.from_bytes(b, byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bxor(b1, b2):\n",
    "    n_b1 = np.frombuffer(b1, dtype='uint8')\n",
    "    n_b2 = np.frombuffer(b2, dtype='uint8')\n",
    "\n",
    "    return (n_b1 ^ n_b2).tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dist(bs0, bs1: bytes) -> int:\n",
    "    xored = bxor(bs0, bs1)\n",
    "    dist = byte_to_int(xored)\n",
    "    if dist == 0:\n",
    "        return n_buckets\n",
    "    return n_buckets-math.floor(math.log2(dist))-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest(t: Trie, k: bytes, n: int):\n",
    "    if t.size == 0:\n",
    "        # TODO: remove me\n",
    "        print(\"error nil trie\")\n",
    "        return\n",
    "    closest = t.n_closest_keys(bytes_to_bitstring(k, l=n_buckets), n)\n",
    "    return [bitstring_to_bytes(bs) for bs in closest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_bucket() is given as input a binary trie t, and an integer n,\n",
    "# it returns a balanced list of n random keys. The list is considered as\n",
    "# balanced because, if possible it will contain the same number of keys,\n",
    "# starting with the prefix \"0\" and \"1\", the same number of prefixes \"00\",\n",
    "# \"01\", \"10\", \"11\" etc.\n",
    "# this function is recursive\n",
    "def balance_bucket(t: Trie, n: int):\n",
    "    if n == 0 or t is None:\n",
    "        # invalid parameters\n",
    "        return []\n",
    "\n",
    "    # number of keys wanted with prefix \"0\" and \"1\"\n",
    "    half = math.ceil(n/2)\n",
    "\n",
    "    # if at least one branc is undefined, we reached a leaf\n",
    "    if t.branch[0] is None or t.branch[1] is None:\n",
    "        # return a list containing the leaf's key\n",
    "        return [t.key]\n",
    "    # if both branches have enough candidates\n",
    "    elif t.branch[0].size >= half and t.branch[1].size >= half:\n",
    "        add0, add1 = 0, 0\n",
    "        # odd number of peers to return, need to select a branch\n",
    "        # to have 1 additional peer\n",
    "        if n % 2 == 1:\n",
    "            if random.randint(0, 1) == 0:\n",
    "                add0 += 1\n",
    "            else:\n",
    "                add1 += 1\n",
    "        # return the union of the n/2 balanced peers starting with\n",
    "        # prefix \"0\" and the n/2 starting with prefix \"1\"\n",
    "        return balance_bucket(t.branch[0], half-add0) + balance_bucket(t.branch[1], half-add1)\n",
    "    # less than half keys with prefix \"1\"\n",
    "    elif t.branch[0].size >= half:\n",
    "        b1 = t.branch[1].size\n",
    "        # return all keys with prefix \"1\", and a balanced list from\n",
    "        # bucket 0\n",
    "        return balance_bucket(t.branch[0], n-b1) + balance_bucket(t.branch[1], b1)\n",
    "    # less than half keys with prefix \"0\"\n",
    "    elif t.branch[1].size >= half:\n",
    "        b0 = t.branch[0].size\n",
    "        # return all keys with prefix \"0\", and a balanced list from\n",
    "        # with prefix \"1\"\n",
    "        return balance_bucket(t.branch[0], b0) + balance_bucket(t.branch[1], n-b0)\n",
    "    else:\n",
    "        # there are less than n keys in t, return all keys\n",
    "        return t.match_prefix_keys(prefix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary trie storing all peers ids\n",
    "sim_trie = Trie()\n",
    "# list of peers for this simulation\n",
    "sim_peers = []\n",
    "\n",
    "# routing table of the simluation with random buckets\n",
    "sim_peers_random = {}\n",
    "# routing table of the simulation with balanced buckets\n",
    "sim_peers_balanced = {}\n",
    "\n",
    "# generate random peerids and populate the binary trie\n",
    "for _ in range(peers_number):\n",
    "    # generate random peerid\n",
    "    peerid = random_key()\n",
    "    # add peerid to peer trie\n",
    "    while not sim_trie.add(bytes_to_bitstring(peerid)):\n",
    "        # add returns false if key already in trie\n",
    "        # generate new identity\n",
    "        peerid = random_key()\n",
    "\n",
    "    # add peerid to list of peerids\n",
    "    sim_peers.append(peerid)\n",
    "\n",
    "    # create entry for peerid in both simulations routing tables\n",
    "    sim_peers_random[peerid] = {}\n",
    "    sim_peers_balanced[peerid] = {}\n",
    "\n",
    "# iterate on all possible buckets, large to small buckets, 0 prefix to 1 prefix\n",
    "for bid in range(closest_bucket):\n",
    "    for i in range(2**(bid+1)):\n",
    "        # prefix of the current bucket\n",
    "        bucket_prefix = int_to_bitstring(i, bid+1)\n",
    "        # all peers falling in this bucket\n",
    "        candidates = sim_trie.match_prefix_keys(bucket_prefix)\n",
    "\n",
    "        # if no candidates, continue\n",
    "        if len(candidates) == 0:\n",
    "            continue\n",
    "\n",
    "        # flip last bit\n",
    "        target_prefix = bucket_prefix[:-1]+str(1-int(bucket_prefix[-1]))\n",
    "\n",
    "        # targets are peers that could use the candidates (of the current bucket)\n",
    "        # in their routing table\n",
    "        targets = sim_trie.match_prefix_keys(target_prefix)\n",
    "\n",
    "\n",
    "        # bucket root is the subtrie representing the bucket\n",
    "        bucket_root = sim_trie.find_trie(bucket_prefix)\n",
    "        if bucket_root is None:\n",
    "            # bucket root could be undefined if subkey not in the trie\n",
    "            # we need to find the closest child\n",
    "            i = 0\n",
    "            while bucket_root is None:\n",
    "                i += 1\n",
    "                # find the first existing parent\n",
    "                bucket_root = sim_trie.find_trie(bucket_prefix[:-i])\n",
    "            # select the appropriate child as the bucket root\n",
    "            bucket_root = bucket_root.branch[int(bucket_prefix[-i+1])]\n",
    "\n",
    "        # iterate on all targets, and define which candidates are selected\n",
    "        # for their bucket\n",
    "        for t in targets:\n",
    "            # if more than `bucket_size` candidates, select `bucket_size` of them\n",
    "            # at random, else take them all\n",
    "            random_bucket = [bitstring_to_bytes(p) for p in \n",
    "                random.sample(candidates, min(bucket_size, len(candidates)))]\n",
    "            # add these peers to t's routing table, in bucket bid\n",
    "            sim_peers_random[bitstring_to_bytes(t)][bid] = random_bucket\n",
    "\n",
    "            # randomly select candidates in a balanced manner\n",
    "            balanced_bucket = [bitstring_to_bytes(p) for p in balance_bucket(bucket_root, min(bucket_size, len(candidates)))]\n",
    "            # add these peers to t's routing table, in bucket bid\n",
    "            sim_peers_balanced[bitstring_to_bytes(t)][bid] = balanced_bucket\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58.4 s for bucket_size = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_n_hops(peer, key, peers, trie):\n",
    "    # closest peers are the peers storing data associated with key\n",
    "    closest_peers = n_closest(trie, key, repl)\n",
    "\n",
    "    # hop count\n",
    "    hop = 0\n",
    "    if peer in closest_peers:\n",
    "        # if peer store is among the closest peers, 0 hop\n",
    "        return hop\n",
    "\n",
    "    # binary trie helping find the closest peers to key in \n",
    "    # the node's routing table\n",
    "    req_trie = Trie()\n",
    "    # bucket id, corresponding to key\n",
    "    bid = log_dist(peer, key)\n",
    "\n",
    "    if bid in peers[peer] and len(peers[peer][bid]) > 0:\n",
    "        # if this bucket is populated, add peers to req_trie\n",
    "        for peer_neighbor in peers[peer][bid]:\n",
    "            req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "    else:\n",
    "        buckets = list(peers[peer].keys())\n",
    "        found_higher = False\n",
    "        for b in range(bid+1, max(buckets)+1):\n",
    "            if b in buckets and len(peers[peer][b]) > 0:\n",
    "                for peer_neighbor in peers[peer][b]:\n",
    "                    req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                    found_higher = True\n",
    "        if not found_higher:\n",
    "            for b in range(bid-1, -1, -1):\n",
    "                if b in buckets and len(peers[peer][b]) > 0:\n",
    "                    for peer_neighbor in peers[peer][b]:\n",
    "                        req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                    break # we are only interested in the closest bucket\n",
    "    if req_trie.size == 0:\n",
    "        print(peers[peer])\n",
    "        print(\"empty trie\")\n",
    "    req_peers = n_closest(req_trie, key, concurrency)\n",
    "\n",
    "    while True:\n",
    "        hop += 1\n",
    "        for c in closest_peers:\n",
    "            if c in req_peers:\n",
    "                return hop\n",
    "\n",
    "        req_trie = Trie()\n",
    "        for p in req_peers:\n",
    "            bid = log_dist(p, key)\n",
    "\n",
    "            if bid in peers[p] and len(peers[p][bid]) > 0:\n",
    "                for peer_neighbor in peers[p][bid]:\n",
    "                    req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "            else:\n",
    "                buckets = list(peers[p].keys())\n",
    "                found_higher = False\n",
    "                for b in range(bid+1, max(buckets)+1):\n",
    "                    if b in buckets and len(peers[p][b]) > 0:\n",
    "                        for peer_neighbor in peers[p][b]:\n",
    "                            req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                            found_higher = True\n",
    "                if not found_higher:\n",
    "                    for b in range(bid-1, -1, -1):\n",
    "                        if b in buckets and len(peers[p][b]) > 0:\n",
    "                            for peer_neighbor in peers[p][b]:\n",
    "                                req_trie.add(bytes_to_bitstring(peer_neighbor, l=n_buckets))\n",
    "                            break # we are only interested in the closest bucket\n",
    "                    \n",
    "        req_peers = n_closest(req_trie, key, 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_random_hop_count = []\n",
    "for i in range(10000):\n",
    "    peer = random.choice(sim_peers)\n",
    "    key = random_key()\n",
    "    n_hop = lookup_n_hops(peer, key, sim_peers_random, sim_trie)\n",
    "    sim_random_hop_count.append(n_hop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9227"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_avg_random = sum(sim_random_hop_count)/len(sim_random_hop_count)\n",
    "sim_avg_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_balanced_hop_count = []\n",
    "for i in range(10000):\n",
    "    peer = random.choice(sim_peers)\n",
    "    key = random_key()\n",
    "    n_hop = lookup_n_hops(peer, key, sim_peers_balanced, sim_trie)\n",
    "    sim_balanced_hop_count.append(n_hop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8973"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_avg_balanced = sum(sim_balanced_hop_count)/len(sim_balanced_hop_count)\n",
    "sim_avg_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average random buckets 1.9227\n",
      "Average balanced buckets 1.8973\n",
      "-0.013387445317029512\n"
     ]
    }
   ],
   "source": [
    "print(\"Average random buckets\", sim_avg_random)\n",
    "print(\"Average balanced buckets\", sim_avg_balanced)\n",
    "print(1-sim_avg_random/sim_avg_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
